{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155250a9",
   "metadata": {},
   "source": [
    "# MLExample: Meal Recommendation End-to-End Pipeline\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Generate and upload meal recommendation training data to S3\n",
    "2. Train a model using SageMaker\n",
    "3. Deploy a serverless inference endpoint on SageMaker\n",
    "4. Deploy an API Gateway with Lambda proxy integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c32e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all parameters for the ML pipeline\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# S3 and SageMaker parameters\n",
    "MEAL_DATA_BUCKET = \"AWS-ML-Example-SDI-bucket123\"\n",
    "SAGEMAKER_ROLE = \"arn:aws:iam::054116116033:role/ml-example-sagemaker-execution-role\"\n",
    "LAMBDA_EXEC_ROLE_ARN = \"arn:aws:iam::054116116033:role/ml-example-lambda-execution-role\"\n",
    "REGION = \"us-west-2\"\n",
    "TRAIN_DATA_KEY = \"meal_data.csv\"\n",
    "MODEL_OUTPUT_PREFIX = \"model/\"\n",
    "ENDPOINT_NAME = \"meal-recommender-serverless-endpoint\"\n",
    "API_GATEWAY_NAME = \"MealRecommenderAPI\"\n",
    "LAMBDA_FUNCTION_NAME = \"MealRecommenderProxy\"\n",
    "\n",
    "# Set environment variables for use in other cells\n",
    "os.environ[\"MEAL_DATA_BUCKET\"] = MEAL_DATA_BUCKET\n",
    "os.environ[\"SAGEMAKER_ROLE\"] = SAGEMAKER_ROLE\n",
    "os.environ[\"LAMBDA_EXEC_ROLE_ARN\"] = LAMBDA_EXEC_ROLE_ARN\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = REGION\n",
    "os.environ[\"AWS_PROFILE\"] = \"rjawsprofile\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5712014",
   "metadata": {},
   "source": [
    "## 1. Generate and Upload Training Data to S3\n",
    "\n",
    "Generate a synthetic meal recommendation dataset and upload it to an S3 bucket for use in SageMaker training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3babdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "os.environ[\"AWS_PROFILE\"] = \"rjawsprofile\"\n",
    "meal_options = {\n",
    "    \"Indian\": [\"Chana Masala\", \"Paneer Tikka\", \"Masala Dosa\", \"Biryani\", \"Dal Makhani\"],\n",
    "    \"American\": [\"Cheeseburger\", \"Grilled Chicken Salad\", \"Mac and Cheese\", \"BBQ Ribs\", \"Pancakes\"],\n",
    "    \"British\": [\"Fish and Chips\", \"Shepherd's Pie\", \"Full English Breakfast\", \"Bangers and Mash\", \"Roast Beef\"],\n",
    "    \"Chinese\": [\"Kung Pao Chicken\", \"Sweet and Sour Pork\", \"Fried Rice\", \"Spring Rolls\", \"Mapo Tofu\"],\n",
    "    \"Mexican\": [\"Tacos\", \"Burrito Bowl\", \"Enchiladas\", \"Quesadillas\", \"Chilaquiles\"]\n",
    "}\n",
    "\n",
    "backgrounds = list(meal_options.keys())\n",
    "times_of_day = [\"Morning\", \"Noon\", \"Evening\", \"Night\"]\n",
    "health_levels = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "rows = []\n",
    "for _ in range(100_000):\n",
    "    background = random.choice(backgrounds)\n",
    "    meal = random.choice(meal_options[background])\n",
    "    time_of_day = random.choice(times_of_day)\n",
    "    family_size = random.choices([1, 2, 3, 4, 5, 6], weights=[0.3, 0.25, 0.2, 0.15, 0.07, 0.03])[0]\n",
    "    health = random.choice(health_levels)\n",
    "    record = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"background\": background,\n",
    "        \"meal\": meal,\n",
    "        \"time_of_day\": time_of_day,\n",
    "        \"family_size\": family_size,\n",
    "        \"health_consciousness\": health,\n",
    "        \"created_at\": (datetime.now() - timedelta(days=random.randint(0, 365))).strftime(\"%Y-%m-%d\")\n",
    "    }\n",
    "    rows.append(record)\n",
    "\n",
    "csv_path = \"meal_data.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Generated {len(rows)} meal records in {csv_path}\")\n",
    "\n",
    "# Upload to S3\n",
    "bucket = os.environ.get(\"MEAL_DATA_BUCKET\")\n",
    "s3_key = \"meal_data.csv\"\n",
    "if bucket:\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.upload_file(csv_path, bucket, s3_key)\n",
    "    print(f\"Uploaded {csv_path} to s3://{bucket}/{s3_key}\")\n",
    "else:\n",
    "    print(\"Set the MEAL_DATA_BUCKET environment variable to upload to S3.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578d7c3",
   "metadata": {},
   "source": [
    "## 2. Train Model Using SageMaker\n",
    "\n",
    "Use the SageMaker Python SDK to launch a training job with the generated meal data in S3. The training script will build a meal recommendation model and save the artifact to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "input_s3 = f\"s3://{MEAL_DATA_BUCKET}/{TRAIN_DATA_KEY}\"\n",
    "output_s3 = f\"s3://{MEAL_DATA_BUCKET}/{MODEL_OUTPUT_PREFIX}\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"src/train.py\",\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    sagemaker_session=sess,\n",
    "    output_path=output_s3,\n",
    "    hyperparameters={}\n",
    ")\n",
    "\n",
    "sklearn_estimator.fit({\"train\": input_s3})\n",
    "print(f\"Model trained and saved to {output_s3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe40495",
   "metadata": {},
   "source": [
    "## 3. Set Up SageMaker Serverless Inference Endpoint\n",
    "\n",
    "Deploy the trained model as a serverless inference endpoint using the SageMaker Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4814db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "model_artifact = sklearn_estimator.model_data\n",
    "\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_artifact,\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    entry_point=\"src/inference.py\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "predictor = sklearn_model.deploy(\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    instance_type=\"ml.m5.large\",  # For serverless, use serverless_inference_config in real use\n",
    "    wait=True\n",
    ")\n",
    "print(f\"SageMaker serverless inference endpoint '{ENDPOINT_NAME}' deployed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf76027",
   "metadata": {},
   "source": [
    "## 4. Deploy API Gateway with Lambda Proxy Integration\n",
    "\n",
    "Create an AWS Lambda function that invokes the SageMaker endpoint, and set up an API Gateway REST API with Lambda proxy integration to expose the inference endpoint as a public API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "REGION = os.environ.get(\"AWS_REGION\")\n",
    "LAMBDA_FUNCTION_NAME = os.environ.get(\"LAMBDA_FUNCTION_NAME\")\n",
    "LAMBDA_EXEC_ROLE_ARN = os.environ.get(\"LAMBDA_EXEC_ROLE_ARN\")\n",
    "ENDPOINT_NAME = os.environ.get(\"SAGEMAKER_ENDPOINT\")\n",
    "API_GATEWAY_NAME = os.environ.get(\"API_GATEWAY_NAME\")\n",
    "\n",
    "lambda_client = boto3.client('lambda', region_name=REGION)\n",
    "apigw_client = boto3.client('apigatewayv2', region_name=REGION)\n",
    "\n",
    "# Package Lambda function\n",
    "with open(\"api/lambda_proxy.py\", \"rb\") as f_in, open(\"lambda_proxy.zip\", \"wb\") as f_out:\n",
    "    with zipfile.ZipFile(f_out, 'w') as zf:\n",
    "        zf.writestr(\"lambda_proxy.py\", f_in.read())\n",
    "\n",
    "# Create Lambda function\n",
    "with open(\"lambda_proxy.zip\", \"rb\") as f:\n",
    "    response = lambda_client.create_function(\n",
    "        FunctionName=LAMBDA_FUNCTION_NAME,\n",
    "        Runtime=\"python3.9\",\n",
    "        Role=LAMBDA_EXEC_ROLE_ARN,\n",
    "        Handler=\"lambda_proxy.lambda_handler\",\n",
    "        Code={\"ZipFile\": f.read()},\n",
    "        Environment={\"Variables\": {\"SAGEMAKER_ENDPOINT\": ENDPOINT_NAME}},\n",
    "        Timeout=30,\n",
    "        MemorySize=256,\n",
    "        Publish=True\n",
    "    )\n",
    "    lambda_arn = response[\"FunctionArn\"]\n",
    "    print(f\"Created Lambda: {lambda_arn}\")\n",
    "\n",
    "# Create API Gateway HTTP API\n",
    "api_response = apigw_client.create_api(\n",
    "    Name=API_GATEWAY_NAME,\n",
    "    ProtocolType=\"HTTP\",\n",
    "    Target=lambda_arn\n",
    ")\n",
    "print(f\"API Gateway endpoint: {api_response['ApiEndpoint']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d69a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and upload meal data to S3 using parameterized variables\n",
    "import random\n",
    "import csv\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "meal_options = {\n",
    "    \"Indian\": [\"Chana Masala\", \"Paneer Tikka\", \"Masala Dosa\", \"Biryani\", \"Dal Makhani\"],\n",
    "    \"American\": [\"Cheeseburger\", \"Grilled Chicken Salad\", \"Mac and Cheese\", \"BBQ Ribs\", \"Pancakes\"],\n",
    "    \"British\": [\"Fish and Chips\", \"Shepherd's Pie\", \"Full English Breakfast\", \"Bangers and Mash\", \"Roast Beef\"],\n",
    "    \"Chinese\": [\"Kung Pao Chicken\", \"Sweet and Sour Pork\", \"Fried Rice\", \"Spring Rolls\", \"Mapo Tofu\"],\n",
    "    \"Mexican\": [\"Tacos\", \"Burrito Bowl\", \"Enchiladas\", \"Quesadillas\", \"Chilaquiles\"]\n",
    "}\n",
    "\n",
    "backgrounds = list(meal_options.keys())\n",
    "times_of_day = [\"Morning\", \"Noon\", \"Evening\", \"Night\"]\n",
    "health_levels = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "rows = []\n",
    "for _ in range(100_000):\n",
    "    background = random.choice(backgrounds)\n",
    "    meal = random.choice(meal_options[background])\n",
    "    time_of_day = random.choice(times_of_day)\n",
    "    family_size = random.choices([1, 2, 3, 4, 5, 6], weights=[0.3, 0.25, 0.2, 0.15, 0.07, 0.03])[0]\n",
    "    health = random.choice(health_levels)\n",
    "    record = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"background\": background,\n",
    "        \"meal\": meal,\n",
    "        \"time_of_day\": time_of_day,\n",
    "        \"family_size\": family_size,\n",
    "        \"health_consciousness\": health,\n",
    "        \"created_at\": (datetime.now() - timedelta(days=random.randint(0, 365))).strftime(\"%Y-%m-%d\")\n",
    "    }\n",
    "    rows.append(record)\n",
    "\n",
    "csv_path = TRAIN_DATA_KEY\n",
    "with open(csv_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Generated {len(rows)} meal records in {csv_path}\")\n",
    "\n",
    "# Upload to S3\n",
    "bucket = MEAL_DATA_BUCKET\n",
    "s3_key = TRAIN_DATA_KEY\n",
    "if bucket:\n",
    "    s3 = boto3.client('s3', region_name=REGION)\n",
    "    s3.upload_file(csv_path, bucket, s3_key)\n",
    "    print(f\"Uploaded {csv_path} to s3://{bucket}/{s3_key}\")\n",
    "else:\n",
    "    print(\"Set the MEAL_DATA_BUCKET environment variable to upload to S3.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
